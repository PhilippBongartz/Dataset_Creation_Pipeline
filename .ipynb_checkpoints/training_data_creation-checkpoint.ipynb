{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af895c53",
   "metadata": {},
   "source": [
    "# Training data creation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2017c",
   "metadata": {},
   "source": [
    "In this notebook we create training data for different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e2028",
   "metadata": {},
   "source": [
    "### piece classification training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66353020",
   "metadata": {},
   "source": [
    "for piece classification and piece color classification we extract boards and squares from videos. We have two ways of labelling them: By recognising starting positions where all piece positions are known and with the CLIP-based classification function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc009c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08561546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from cv2 import CAP_PROP_FRAME_COUNT, CAP_PROP_POS_FRAMES\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.video_utils import *\n",
    "from src.board_extraction import *\n",
    "from src.game_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa707da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'videos'\n",
    "banter_videos = []\n",
    "\n",
    "import os\n",
    "count = 0\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "        if filepath.endswith(\".mp4\") and ('banter' in filepath or 'Banter' in filepath):\n",
    "            banter_videos.append(filepath)\n",
    "            count+=1\n",
    "print(f\"\"\"{count} banter blitz videos.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc61c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier sammeln wir bretter und startpositions: naja, erstmal nur bretter mit num\n",
    "# Am schlauesten wird das schon direkt rausgeschrieben. \n",
    "\n",
    "save_file = '/home/user/Schreibtisch/Youtube_Scrapen_Repo/Youtube_Scrapen/bretter_images/'\n",
    "\n",
    "count = 0\n",
    "for i,video_path in enumerate(banter_videos[15:]):\n",
    "    i = i + 15\n",
    "    try:\n",
    "        n = 10000\n",
    "        board = None\n",
    "        frame_number = 0\n",
    "        for frame in read_every_nth_frame(video_path, n):\n",
    "            if board is None:\n",
    "                board = largest_board_extraction(frame)\n",
    "            if board is not None:\n",
    "                brett = schachbrett_auschneiden(frame,board)\n",
    "\n",
    "                fb = board[2]\n",
    "                num = empty_middle_squares(fb,brett)\n",
    "\n",
    "                file_name = f\"\"\"vid_{i}_frame_{frame_number}_num{num}_fb_{fb}.jpeg\"\"\"\n",
    "\n",
    "                cv2.imwrite(save_file+file_name,brett)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "                #bretter.append((brett,fb,num))\n",
    "                #plotting(brett,title=str(num)+' '+str(frame_number))\n",
    "                print(i,count)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "                #plotting(frame)\n",
    "\n",
    "            frame_number += n\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier lesen wir alles wieder ein und sieben die nicht-bretter aus:\n",
    "# \n",
    "folder_path = '/home/user/Schreibtisch/Youtube_Scrapen_Repo/Youtube_Scrapen/bretter_images/'\n",
    "\n",
    "def parse_bretter_images(file_name):\n",
    "    entries = file_name.split('_')\n",
    "    video = int(entries[1])\n",
    "    frame = int(entries[3])\n",
    "    num   = int(entries[4][3:])\n",
    "    fb    = int(entries[6][:-5])\n",
    "    return (video,frame,num,fb)\n",
    "    \n",
    "for _,_,files in os.walk(folder_path):\n",
    "    break\n",
    "\n",
    "count = 0\n",
    "for file in files:\n",
    "    (video,frame,num,fb) = parse_bretter_images(file)\n",
    "    if num == 32:\n",
    "        count += 1\n",
    "        \n",
    "len(files)*64\n",
    "count*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64809160",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_it_board_text = open_clip.tokenize([\"a full chessboard without edge\",\n",
    "                               \"part of a chessboard with an edge beyond\",\n",
    "                               \"a person\", \n",
    "                               \"a graphic\"])\n",
    "\n",
    "is_it_board_text_features = model.encode_text(is_it_board_text)\n",
    "is_it_board_text_features /= is_it_board_text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "def is_it_a_board_classification(brett):\n",
    "    image = Image.fromarray(brett)\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_probs = (100.0 * image_features @ is_it_board_text_features.T).softmax(dim=-1)\n",
    "        \n",
    "    return text_probs[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unoptimiert: 1000 2.1150066534678142 min\n",
    "# text pre-encoded: 1000 0.6793083985646565 min\n",
    "\n",
    "# ist gepickelt riesig - nachher löschen.\n",
    "\n",
    "import pickle\n",
    "\n",
    "count = 0\n",
    "start_time = time.time()\n",
    "eval_images = []\n",
    "for i,file in enumerate(os.listdir(folder_path)):\n",
    "    if file.endswith('jpeg'):\n",
    "        im = cv2.imread(folder_path+file)\n",
    "        \n",
    "        #resized = cv2.resize(im, (64,64), interpolation = cv2.INTER_AREA)\n",
    "        #gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        #reshaped = gray.reshape((64,64,1))\n",
    "\n",
    "        #category = file.split('_')[2]\n",
    "        #label = label2array[category]\n",
    "        #image = reshaped\n",
    "        classification = is_it_a_board_classification(im)\n",
    "        \n",
    "        eval_images.append((classification[0],classification,im,file))\n",
    "        \n",
    "        if i%10000 == 0:\n",
    "            print(i,(time.time()-start_time)/60,'min')\n",
    "            pickle.dump(eval_images,open('eval_images.pickle','wb'))\n",
    "        \n",
    "        #if classification[0] < 0.95:\n",
    "        #    plotting(im,title=str(classification[0])+' '+str(i))\n",
    "        #    count += 1\n",
    "        #if count > 20:\n",
    "        #    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "eval_images.sort(key=itemgetter(0))    \n",
    "\n",
    "\n",
    "#for (score,classi,im,file_name) in eval_images[3000:3100]:\n",
    "#    plotting(im,title=str(score))\n",
    "\n",
    "eval_images[7000][0]\n",
    "#len(eval_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb37f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier optimieren wir mal which color is being played: \n",
    "# Da könnten wir auch eine zweite Version auf basis des classifiers bauen ... \n",
    "\n",
    "@overall_runtime\n",
    "def get_square(square, fb, gray_board):\n",
    "    letters = 'ABCDEFGH'\n",
    "    i1 = letters.index(square[0])\n",
    "    i2 = int(square[1])\n",
    "\n",
    "    x1 = round(fb * (8 - i2))\n",
    "    x2 = round(fb * (8 - i2) + fb)\n",
    "\n",
    "    y1 = round(fb * i1)\n",
    "    y2 = round(fb * i1 + fb)\n",
    "\n",
    "    return gray_board[x1:x2, y1:y2]\n",
    "\n",
    "@overall_runtime\n",
    "def which_color_is_being_played(fb, brett):\n",
    "    \"\"\"\n",
    "    Aka upper_vs_lower_squares_brightness\n",
    "    This function checks whether the upper or the lower squares are brighter.\n",
    "    In the starting position this tells us whether white or black is being played.\n",
    "    TODO: Don't get_square for all separately, but get top part of board etc.\n",
    "    \"\"\"\n",
    "    upper_mean = 0.0\n",
    "    for square in upper_squares:\n",
    "        square_img = get_square(square, fb, brett)\n",
    "        upper_mean += np.mean(square_img)\n",
    "\n",
    "    lower_mean = 0.0\n",
    "    for square in lower_squares:\n",
    "        square_img = get_square(square, fb, brett)\n",
    "        lower_mean += np.mean(square_img)\n",
    "\n",
    "    if lower_mean > upper_mean:\n",
    "        return \"white\"\n",
    "    return \"black\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier bauen wir aus den start positions ein validation set\n",
    "# Wir kuratieren es manuell --> keine Fehler.\n",
    "\n",
    "manuell_aussortiert = [16,22,41,71,539,548,563,564,587,605]\n",
    "validation_set = []\n",
    "for (score,classi,im,file_name) in eval_images[7000:]:\n",
    "    (video,frame,num,fb) = parse_bretter_images(file_name)\n",
    "    if num==32:\n",
    "        which_color = which_color_is_being_played(fb, im)\n",
    "        validation_set.append((im,file_name,video,frame,num,fb, which_color))\n",
    "        plotting(im,title=str(len(validation_set)-1)+which_color)\n",
    "len(validation_set)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier die manuelle kuration:\n",
    "kuratiertes_evaluation_set = []\n",
    "\n",
    "for i,(im,file_name,video,frame,num,fb, which_color) in enumerate(validation_set):\n",
    "    if i+1 in [16,22,41,71,539,548,563,564,587,605]:\n",
    "        plotting(im,title=str(which_color))\n",
    "    else:\n",
    "        kuratiertes_evaluation_set.append((im,file_name,video,frame,num,fb, which_color))\n",
    "\n",
    "len(kuratiertes_evaluation_set)*64\n",
    "\n",
    "pickle.dump(kuratiertes_evaluation_set,open('evaluation_data_squares.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c22864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier labeln wir den rest mit der Clip-Funktion (oder mit dem tf-model?)\n",
    "start_time = time.time()\n",
    "training_data = []\n",
    "for i,(score,classi,im,file_name) in enumerate(eval_images[7000:]):\n",
    "    (video,frame,num,fb) = parse_bretter_images(file_name)\n",
    "    if num!=32:\n",
    "        prob_pos = probabilistic_position(im)\n",
    "\n",
    "        index = 0\n",
    "        for r in '87654321':\n",
    "            for c in 'ABCDEFGH':\n",
    "                color_prob = prob_pos[index][0]\n",
    "                piece_prob = prob_pos[index][1]\n",
    "                square = get_square(c + r, fb, im)\n",
    "                \n",
    "                color = ['W', 'B'][color_prob.argmax()]\n",
    "                piece = ['N','Q','K','R','B','P','E'][piece_prob.argmax()]\n",
    "                \n",
    "                training_data.append((square,file_name,video,frame,num,fb,color,piece,c+r))\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "        if i%1000==0:\n",
    "            print(i,time.time()-start_time)\n",
    "            pickle.dump(training_data,open('training_data_squares.pickle','wb'))\n",
    "            \n",
    "pickle.dump(training_data,open('training_data_squares.pickle','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b742f",
   "metadata": {},
   "source": [
    "### Hier basteln wir zwei Order mit Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6aa1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "import pickle\n",
    "\n",
    "training_data = pickle.load(open('training_data_squares.pickle','rb'))\n",
    "\n",
    "print(len(training_data))\n",
    "\n",
    "folder = '/home/user/Schreibtisch/PieceClassification/square_images_color_piece/'\n",
    "for i,(im,file,vid,fra,num,fb,col,piec,sq) in enumerate(training_data):\n",
    "    sample_path = f\"\"\"square_{i}_{col}_{piec}.jpeg\"\"\"\n",
    "    cv2.imwrite(folder+sample_path, im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46844ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "kuratiertes_evaluation_set = pickle.load(open('evaluation_data_squares.pickle','rb'))\n",
    "folder = '/home/user/Schreibtisch/PieceClassification/square_images_color_piece_evaluation/'\n",
    "\n",
    "i = 0\n",
    "for (im,file_name,video,frame,num,fb, which_color) in kuratiertes_evaluation_set:\n",
    "    for r in '87654321':\n",
    "        for c in 'ABCDEFGH':\n",
    "            square = get_square(c + r, fb, im)\n",
    "            if r in '3456':\n",
    "                piece = 'E'\n",
    "                color = 'N'\n",
    "            if r in '27':\n",
    "                piece = 'P'\n",
    "            if r in '18':\n",
    "                if c in 'AH':\n",
    "                    piece = 'R'\n",
    "                if c in 'BG':\n",
    "                    piece = 'N'\n",
    "                if c in 'CF':\n",
    "                    piece = 'B'\n",
    "                if c == 'D':\n",
    "                    if which_color == 'white':\n",
    "                        piece = 'Q'\n",
    "                    if which_color == 'black':\n",
    "                        piece = 'K'\n",
    "                if c == 'E':\n",
    "                    if which_color == 'white':\n",
    "                        piece = 'K'\n",
    "                    if which_color == 'black':\n",
    "                        piece = 'Q'       \n",
    "            \n",
    "            if r in '12':\n",
    "                if which_color == 'black':\n",
    "                    color = 'b'\n",
    "                if which_color == 'white':\n",
    "                    color = 'w'\n",
    "            if r in '78':\n",
    "                if which_color == 'black':\n",
    "                    color = 'w'\n",
    "                if which_color == 'white':\n",
    "                    color = 'b'          \n",
    "            \n",
    "            sample_path = f\"\"\"square_{i}_{color}_{piece}.jpeg\"\"\"\n",
    "            i = i+1\n",
    "            cv2.imwrite(folder+sample_path, square)\n",
    "            \n",
    "            #plotting(square,title = sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kuratiertes_evaluation_set)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad509863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b78f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0410dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_scrape",
   "language": "python",
   "name": "yt_scrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
