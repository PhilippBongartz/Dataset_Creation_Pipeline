{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2e37f7",
   "metadata": {},
   "source": [
    "# Self-Distillation mit großem Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ad3ca",
   "metadata": {},
   "source": [
    "In dieser Version habe ich nicht nur einen großen Datensatz, sondern auch ein großes fehlerfreies Evaluationsset und Farbe und Art der Figuren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8cd5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:07:18.047763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 12:07:18.882172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-02-27 12:07:18.882212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-02-27 12:07:18.882216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690aed1",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e1aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2array = {\n",
    "     'WB' : np.array([1,0,0,0,0,0,0,0,0,0,0,0,0]), \n",
    "     'E'  : np.array([0,1,0,0,0,0,0,0,0,0,0,0,0]), \n",
    "     'WK' : np.array([0,0,1,0,0,0,0,0,0,0,0,0,0]), \n",
    "     'WN' : np.array([0,0,0,1,0,0,0,0,0,0,0,0,0]), \n",
    "     'WP' : np.array([0,0,0,0,1,0,0,0,0,0,0,0,0]), \n",
    "     'WQ' : np.array([0,0,0,0,0,1,0,0,0,0,0,0,0]), \n",
    "     'WR' : np.array([0,0,0,0,0,0,1,0,0,0,0,0,0]),\n",
    "     'BB' : np.array([0,0,0,0,0,0,0,1,0,0,0,0,0]), \n",
    "     'BK' : np.array([0,0,0,0,0,0,0,0,1,0,0,0,0]), \n",
    "     'BN' : np.array([0,0,0,0,0,0,0,0,0,1,0,0,0]), \n",
    "     'BP' : np.array([0,0,0,0,0,0,0,0,0,0,1,0,0]), \n",
    "     'BQ' : np.array([0,0,0,0,0,0,0,0,0,0,0,1,0]), \n",
    "     'BR' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,1]) }\n",
    "\n",
    "label2piece = {\n",
    "     0:'WB',\n",
    "     1:'E',\n",
    "     2:'WK',\n",
    "     3:'WN',\n",
    "     4:'WP',\n",
    "     5:'WQ',\n",
    "     6:'WR',\n",
    "     7:'BB',\n",
    "     8:'BK',\n",
    "     9:'BN',\n",
    "    10:'BP',\n",
    "    11:'BQ',\n",
    "    12:'BR' }\n",
    "\n",
    "# Test:\n",
    "for label in label2array:\n",
    "    index = label2array[label].argmax()\n",
    "    if label2piece[index] != label:\n",
    "        print(label2piece[index] ,label, index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59b1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    \n",
    "    categories = []\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('jpeg'):\n",
    "            im = cv2.imread(path+\"/\"+file)\n",
    "            resized = cv2.resize(im, (64,64), interpolation = cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "            reshaped = gray.reshape((64,64,1))\n",
    "\n",
    "            color = file.split('_')[2].upper()\n",
    "            piece = file.split('_')[3][:1].upper()\n",
    "\n",
    "            if piece != 'E': \n",
    "                category = color + piece\n",
    "            else:\n",
    "                category = 'E'\n",
    "                \n",
    "            label = label2array[category]\n",
    "            image = reshaped\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return (images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f87dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190208 (64, 64, 1) (13,)\n"
     ]
    }
   ],
   "source": [
    "path = \"square_images_color_piece\"\n",
    "\n",
    "train_images, train_labels = load_data(path)\n",
    "\n",
    "print(len(train_images),train_images[0].shape,train_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f15222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38080 (64, 64, 1) (13,)\n"
     ]
    }
   ],
   "source": [
    "path = \"square_images_color_piece_evaluation\"\n",
    "\n",
    "test_images, test_labels = load_data(path)\n",
    "\n",
    "print(len(test_images),test_images[0].shape,test_labels[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d31837",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8091ae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38080, 64, 64, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0,:,:,:].shape\n",
    "type(test_images[0,:,:,:])\n",
    "type(test_images[0,0,0,0])\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc43718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model():\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "                  learning_rate = 0.001\n",
    "                )\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(13, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecef37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cddf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_images, train_labels, eval_data, eval_labels, epochs=1, batch_size=32):\n",
    "    train_generator = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "    model.fit(train_generator, \n",
    "              steps_per_epoch=len(train_images) // batch_size, \n",
    "              validation_data = (eval_data,eval_labels), \n",
    "              epochs=epochs\n",
    "             )\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ffbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(model,images):\n",
    "    output = model.predict(images)\n",
    "    num_of_samples = output.shape[0]\n",
    "    new_labels = np.zeros((num_of_samples,7))\n",
    "    new_label_indices = np.argmax(output,axis=1)\n",
    "    for i,index in enumerate(new_label_indices):\n",
    "        new_labels[i,index] = 1.0\n",
    "    return new_labels\n",
    "\n",
    "def evaluate(model,train_images,train_labels):\n",
    "    results = model.evaluate(train_images,train_labels)\n",
    "    return np.array(results)\n",
    "\n",
    "def sanity_check(train_labels,train_labels_x):\n",
    "    num_labels = train_labels.shape[0]\n",
    "    count = 0\n",
    "    for t in range(num_labels):\n",
    "        if (train_labels[t] == train_labels_x[t]).all():\n",
    "            count += 1\n",
    "    print('Sanity check:',count/num_labels)\n",
    "    return count/num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac332e02",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d51fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 05:56:11.504399: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f10700291a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-23 05:56:11.504423: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-23 05:56:11.514091: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-23 05:56:11.629064: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37194/37194 [==============================] - 301s 8ms/step - loss: 0.4998 - accuracy: 0.9004 - val_loss: 0.9527 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f135195ad00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model()\n",
    "\n",
    "train_model(model, train_images, train_labels, test_images, test_labels, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa7c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 17:30:57.773312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-23 17:30:59.198819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-23 17:30:59.208238: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x49c68b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-23 17:30:59.208254: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-23 17:30:59.218332: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-23 17:30:59.342577: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 11s 9ms/step - loss: 0.5272 - accuracy: 0.8405 - val_loss: 0.0485 - val_accuracy: 0.9921\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.1206 - accuracy: 0.9642 - val_loss: 0.0191 - val_accuracy: 0.9961\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.0745 - accuracy: 0.9787 - val_loss: 0.0131 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.0473 - accuracy: 0.9870 - val_loss: 0.0122 - val_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.0456 - accuracy: 0.9874 - val_loss: 0.0117 - val_accuracy: 0.9979\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 8s 10ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.0169 - val_accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.0119 - val_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 7s 9ms/step - loss: 0.0261 - accuracy: 0.9936 - val_loss: 0.0075 - val_accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 7s 9ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 7s 9ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.0060 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fd5edf0d400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model()\n",
    "\n",
    "train_model(model, test_images[:25000], test_labels[:25000], test_images[25000:], test_labels[25000:], epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdd8b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37194/37194 [==============================] - 48s 1ms/step - loss: 5.5251 - accuracy: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.525136947631836, 0.9474411010742188]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb831c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37194/37194 [==============================] - 32s 868us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1190208, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ein Plan: model auf test-daten trainiert auf train_data anwenden:\n",
    "# Die Samples rauschmeißen wo vorhersage und label sich widersprechen\n",
    "# Dann auf dem Datensatz trainieren ...\n",
    "\n",
    "new_labels = model.predict(train_images)\n",
    "\n",
    "new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45305ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75910161e-16, 3.72638084e-14, 6.55198823e-14, 1.19914675e-14,\n",
       "       5.77327411e-13, 7.72137636e-19, 2.17027163e-15, 2.09013024e-07,\n",
       "       2.55748574e-13, 7.43772048e-08, 9.99999642e-01, 4.84452659e-16,\n",
       "       5.19559007e-10], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e401879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.astype('float32')[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe6f8723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1126843, 64, 64, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_images = []\n",
    "new_train_labels = []\n",
    "for t in range(new_labels.shape[0]):\n",
    "    if train_labels[t,:].argmax() == new_labels[t,:].argmax():\n",
    "        new_train_images.append(train_images[t,:])\n",
    "        new_train_labels.append(train_labels[t,:])\n",
    "\n",
    "new_train_images = np.array(new_train_images)\n",
    "new_train_labels = np.array(new_train_labels)\n",
    "        \n",
    "new_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59728f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17606/17606 [==============================] - 267s 15ms/step - loss: 0.0202 - accuracy: 0.9963 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 2/5\n",
      "17606/17606 [==============================] - 270s 15ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 0.0068 - val_accuracy: 0.9991\n",
      "Epoch 3/5\n",
      "17606/17606 [==============================] - 269s 15ms/step - loss: 0.0375 - accuracy: 0.9934 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
      "Epoch 4/5\n",
      "17606/17606 [==============================] - 268s 15ms/step - loss: 0.0414 - accuracy: 0.9926 - val_loss: 0.0124 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "17606/17606 [==============================] - 266s 15ms/step - loss: 0.0476 - accuracy: 0.9921 - val_loss: 0.0049 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fd46010a100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = make_model()\n",
    "\n",
    "train_model(model, new_train_images, new_train_labels, test_images, test_labels, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd8f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: piece_color_classification_09994/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: piece_color_classification_09994/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('piece_color_classification_09994')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2b36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
